{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import codecs\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_index(samples, targets):\n",
    "    nearest_index_list = []\n",
    "    for target in targets:\n",
    "        differences = np.abs(samples - target)\n",
    "        nearest_index = np.argmin(differences)\n",
    "        nearest_index_list.append(nearest_index)\n",
    "    return nearest_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 925/925 [00:27<00:00, 33.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# initialize constants\n",
    "tab_char = '\\t'\n",
    "indentation_char = '\\r\\n'\n",
    "delimiter = ''\n",
    "num_samples_per_data = 6887\n",
    "\n",
    "# initialize variables\n",
    "peak_table_start_row_index = 0\n",
    "peak_table_end_row_index = 0\n",
    "composed_result_start_row_index = 0\n",
    "composed_result_end_row_index = 0\n",
    "wave_start_row_index = 0\n",
    "wave_end_row_index = 0\n",
    "\n",
    "data_dir = './gas-chromatograph-txt'\n",
    "file_ext = '.TXT'\n",
    "monthly_dir_list = glob.glob(data_dir + '/*')\n",
    "filepath_list = []\n",
    "for monthly_dir in monthly_dir_list:\n",
    "    filepath_list += glob.glob(monthly_dir + '/*' + file_ext)\n",
    "    \n",
    "intensities_list = []\n",
    "labels_list = []\n",
    "for filepath in tqdm(filepath_list):\n",
    "#     print('filepath -> {}'.format(filepath))\n",
    "    df = pd.read_csv(\n",
    "        filepath, \n",
    "        sep='\\t',\n",
    "        names=[\"c1\", \"c2\", \"c3\", \"c4\", \"c5\", \"c6\", \"c7\", \"c8\", \"c9\", \"c10\"],\n",
    "        encoding='cp932'\n",
    "    )\n",
    "#     display(df.head())\n",
    "    wave_start_index = df.query('c1 == \"R.Time\"').index.values[0]\n",
    "    wave_df = pd.DataFrame(\n",
    "        df[['c1', 'c2']][wave_start_index+1:-3].values,\n",
    "        columns=df.loc[wave_start_index, ['c1', 'c2']].values\n",
    "    )\n",
    "#     display(wave_df)\n",
    "    peak_table_start_index = df.query('c1 == \"[Peak Table (Ch1)]\"').index.values[0]\n",
    "    peak_table_end_index = df.query('c1 == \"[Compound Results (Ch1)]\"').index.values[0]\n",
    "#     print('peak_table_end_index - peak_table_start_index -> {}'.format(peak_table_end_index - peak_table_start_index))\n",
    "    if peak_table_end_index - peak_table_start_index <= 2:\n",
    "        continue\n",
    "    peak_df = pd.DataFrame(\n",
    "        df[peak_table_start_index+3:peak_table_end_index].values,\n",
    "        columns=df.loc[peak_table_start_index+2].values\n",
    "    )\n",
    "#     display(peak_df)\n",
    "    times = wave_df['R.Time'].values.astype(float)\n",
    "    intensities = wave_df['Intensity'].values.astype(float)\n",
    "#     plt.figure(figsize=(16,4))\n",
    "#     plt.plot(times, intensities)\n",
    "    peak_start_times = [float(time) for time in peak_df['I.Time']]\n",
    "    peak_start_index_list = find_nearest_index(times, peak_start_times)\n",
    "    for peak_start_index, peak_start_time in zip(peak_start_index_list, peak_start_times):\n",
    "#         print('peak start time (from peak table) -> {}'.format(peak_start_time))\n",
    "        differences = np.abs(times - peak_start_time)\n",
    "#         print('peak start time -> {}'.format(times[peak_start_index]))\n",
    "#         plt.axvline(x=times[peak_start_index], color='red')\n",
    "#     plt.show()\n",
    "    labels = np.zeros(times.shape[0])\n",
    "    labels[peak_start_index_list] = 1\n",
    "    if len(intensities) == num_samples_per_data:\n",
    "        intensities_list.append(intensities)\n",
    "        labels_list.append(labels)\n",
    "intensities_array = np.array(intensities_list)\n",
    "labels_array = np.array(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(898, 6887)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intensities_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(samples, labels):\n",
    "    window_length = 101\n",
    "    num_samples = samples.shape[0]\n",
    "    maximum = num_samples - np.floor(window_length/2)\n",
    "    minimum = np.floor(window_length/2)\n",
    "    label_index = int((maximum - minimum) * np.random.rand() + minimum)\n",
    "    return samples[int(label_index-np.floor(window_length/2)):int(label_index+np.floor(window_length/2))], labels[label_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    samples = intensities_array[0]\n",
    "    labels = labels_array[0]\n",
    "    cropped_samples, label = preprocess(samples, labels)\n",
    "    if label==1:\n",
    "        print(cropped_samples, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 101\n",
    "dataset = tf.data.Dataset.from_tensor_slices((intensities_array, labels_array))\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "num_samples = intensities_array.shape[0]\n",
    "steps_per_epoch = np.ceil(num_samples/BATCH_SIZE)\n",
    "# dataset = dataset.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "dataset = dataset.shuffle(buffer_size=num_samples)\n",
    "dataset = dataset.repeat()\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = intensities_array[0].shape[0]\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(sample_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(sample_size, activation='sigmoid')\n",
    "])\n",
    "    \n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(), \n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 11s 374ms/step - loss: 74.2373 - accuracy: 0.0528\n",
      "Epoch 2/1000\n",
      "29/29 [==============================] - 12s 425ms/step - loss: 0.6730 - accuracy: 0.2209\n",
      "Epoch 3/1000\n",
      "29/29 [==============================] - 11s 382ms/step - loss: 0.6592 - accuracy: 0.2231\n",
      "Epoch 4/1000\n",
      "29/29 [==============================] - 10s 357ms/step - loss: 0.6456 - accuracy: 0.2177\n",
      "Epoch 5/1000\n",
      "29/29 [==============================] - 10s 349ms/step - loss: 0.6322 - accuracy: 0.2241\n",
      "Epoch 6/1000\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.6195 - accuracy: 0.2144\n",
      "Epoch 7/1000\n",
      "29/29 [==============================] - 9s 315ms/step - loss: 0.6065 - accuracy: 0.2058\n",
      "Epoch 8/1000\n",
      "29/29 [==============================] - 10s 333ms/step - loss: 0.5945 - accuracy: 0.2306\n",
      "Epoch 9/1000\n",
      "29/29 [==============================] - 9s 317ms/step - loss: 0.5820 - accuracy: 0.2112\n",
      "Epoch 10/1000\n",
      "29/29 [==============================] - 12s 397ms/step - loss: 0.5701 - accuracy: 0.2155\n",
      "Epoch 11/1000\n",
      "29/29 [==============================] - 10s 355ms/step - loss: 0.5589 - accuracy: 0.2328\n",
      "Epoch 12/1000\n",
      "29/29 [==============================] - 10s 341ms/step - loss: 0.5472 - accuracy: 0.2144\n",
      "Epoch 13/1000\n",
      "29/29 [==============================] - 13s 437ms/step - loss: 0.5362 - accuracy: 0.2209\n",
      "Epoch 14/1000\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 0.5252 - accuracy: 0.2263\n",
      "Epoch 15/1000\n",
      "29/29 [==============================] - 9s 319ms/step - loss: 0.5148 - accuracy: 0.2220\n",
      "Epoch 16/1000\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.5044 - accuracy: 0.2058\n",
      "Epoch 17/1000\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.4944 - accuracy: 0.2295\n",
      "Epoch 18/1000\n",
      "29/29 [==============================] - 8s 291ms/step - loss: 0.4843 - accuracy: 0.2144\n",
      "Epoch 19/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.4748 - accuracy: 0.2177\n",
      "Epoch 20/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.4653 - accuracy: 0.2252\n",
      "Epoch 21/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.4561 - accuracy: 0.2091\n",
      "Epoch 22/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.4470 - accuracy: 0.2155\n",
      "Epoch 23/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.4384 - accuracy: 0.2349\n",
      "Epoch 24/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.4296 - accuracy: 0.2220\n",
      "Epoch 25/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.4215 - accuracy: 0.2155\n",
      "Epoch 26/1000\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.4130 - accuracy: 0.2091\n",
      "Epoch 27/1000\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.4049 - accuracy: 0.2252\n",
      "Epoch 28/1000\n",
      "29/29 [==============================] - 9s 310ms/step - loss: 0.3972 - accuracy: 0.2220\n",
      "Epoch 29/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.3895 - accuracy: 0.2177\n",
      "Epoch 30/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.3821 - accuracy: 0.2198\n",
      "Epoch 31/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.3747 - accuracy: 0.2220\n",
      "Epoch 32/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.3676 - accuracy: 0.2198\n",
      "Epoch 33/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.3605 - accuracy: 0.2166\n",
      "Epoch 34/1000\n",
      "29/29 [==============================] - 9s 306ms/step - loss: 0.3539 - accuracy: 0.2241\n",
      "Epoch 35/1000\n",
      "29/29 [==============================] - 10s 355ms/step - loss: 0.3470 - accuracy: 0.2220\n",
      "Epoch 36/1000\n",
      "29/29 [==============================] - 9s 326ms/step - loss: 0.3406 - accuracy: 0.2058\n",
      "Epoch 37/1000\n",
      "29/29 [==============================] - 11s 390ms/step - loss: 0.3341 - accuracy: 0.2231\n",
      "Epoch 38/1000\n",
      "29/29 [==============================] - 16s 544ms/step - loss: 0.3279 - accuracy: 0.2338\n",
      "Epoch 39/1000\n",
      "29/29 [==============================] - 13s 458ms/step - loss: 0.3222 - accuracy: 0.2037\n",
      "Epoch 40/1000\n",
      "29/29 [==============================] - 11s 390ms/step - loss: 0.3159 - accuracy: 0.2241\n",
      "Epoch 41/1000\n",
      "29/29 [==============================] - 12s 397ms/step - loss: 0.3102 - accuracy: 0.2047\n",
      "Epoch 42/1000\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 0.3043 - accuracy: 0.2360\n",
      "Epoch 43/1000\n",
      "29/29 [==============================] - 10s 350ms/step - loss: 0.2988 - accuracy: 0.2112\n",
      "Epoch 44/1000\n",
      "29/29 [==============================] - 11s 379ms/step - loss: 0.2935 - accuracy: 0.2198\n",
      "Epoch 45/1000\n",
      "29/29 [==============================] - 11s 375ms/step - loss: 0.2882 - accuracy: 0.2101\n",
      "Epoch 46/1000\n",
      "29/29 [==============================] - 16s 557ms/step - loss: 0.2831 - accuracy: 0.2360\n",
      "Epoch 47/1000\n",
      "29/29 [==============================] - 10s 341ms/step - loss: 0.2778 - accuracy: 0.2220\n",
      "Epoch 48/1000\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.2729 - accuracy: 0.2263\n",
      "Epoch 49/1000\n",
      "29/29 [==============================] - 9s 309ms/step - loss: 0.2680 - accuracy: 0.2047\n",
      "Epoch 50/1000\n",
      "29/29 [==============================] - 9s 307ms/step - loss: 0.2634 - accuracy: 0.2123\n",
      "Epoch 51/1000\n",
      "29/29 [==============================] - 9s 304ms/step - loss: 0.2586 - accuracy: 0.2328\n",
      "Epoch 52/1000\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.2541 - accuracy: 0.2209\n",
      "Epoch 53/1000\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.2496 - accuracy: 0.2155\n",
      "Epoch 54/1000\n",
      "29/29 [==============================] - 9s 308ms/step - loss: 0.2452 - accuracy: 0.2231\n",
      "Epoch 55/1000\n",
      "29/29 [==============================] - 10s 328ms/step - loss: 0.2411 - accuracy: 0.2231\n",
      "Epoch 56/1000\n",
      "29/29 [==============================] - 14s 491ms/step - loss: 0.2368 - accuracy: 0.2112\n",
      "Epoch 57/1000\n",
      "29/29 [==============================] - 14s 482ms/step - loss: 0.2327 - accuracy: 0.2220\n",
      "Epoch 58/1000\n",
      "29/29 [==============================] - 13s 458ms/step - loss: 0.2287 - accuracy: 0.2209\n",
      "Epoch 59/1000\n",
      "29/29 [==============================] - 14s 493ms/step - loss: 0.2249 - accuracy: 0.2144\n",
      "Epoch 60/1000\n",
      "29/29 [==============================] - 10s 343ms/step - loss: 0.2209 - accuracy: 0.2209\n",
      "Epoch 61/1000\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.2172 - accuracy: 0.2188\n",
      "Epoch 62/1000\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.2135 - accuracy: 0.2134\n",
      "Epoch 63/1000\n",
      "29/29 [==============================] - 11s 379ms/step - loss: 0.2101 - accuracy: 0.2220\n",
      "Epoch 64/1000\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 0.2065 - accuracy: 0.2241\n",
      "Epoch 65/1000\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.2030 - accuracy: 0.2188\n",
      "Epoch 66/1000\n",
      "29/29 [==============================] - 12s 427ms/step - loss: 0.1996 - accuracy: 0.2263\n",
      "Epoch 67/1000\n",
      "29/29 [==============================] - 13s 432ms/step - loss: 0.1962 - accuracy: 0.2123\n",
      "Epoch 68/1000\n",
      "29/29 [==============================] - 14s 472ms/step - loss: 0.1930 - accuracy: 0.2134\n",
      "Epoch 69/1000\n",
      "29/29 [==============================] - 11s 367ms/step - loss: 0.1900 - accuracy: 0.2263\n",
      "Epoch 70/1000\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.1868 - accuracy: 0.2231\n",
      "Epoch 71/1000\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.1837 - accuracy: 0.2231\n",
      "Epoch 72/1000\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.1807 - accuracy: 0.2166\n",
      "Epoch 73/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.1779 - accuracy: 0.2231\n",
      "Epoch 74/1000\n",
      "29/29 [==============================] - 8s 291ms/step - loss: 0.1750 - accuracy: 0.2004\n",
      "Epoch 75/1000\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.1722 - accuracy: 0.2284\n",
      "Epoch 76/1000\n",
      "29/29 [==============================] - 8s 284ms/step - loss: 0.1694 - accuracy: 0.2144\n",
      "Epoch 77/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.1666 - accuracy: 0.2252\n",
      "Epoch 78/1000\n",
      "29/29 [==============================] - 8s 286ms/step - loss: 0.1641 - accuracy: 0.2220\n",
      "Epoch 79/1000\n",
      "29/29 [==============================] - 8s 291ms/step - loss: 0.1615 - accuracy: 0.2274\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 8s 283ms/step - loss: 0.1588 - accuracy: 0.2069\n",
      "Epoch 81/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.1564 - accuracy: 0.2112\n",
      "Epoch 82/1000\n",
      "29/29 [==============================] - 8s 291ms/step - loss: 0.1540 - accuracy: 0.2209\n",
      "Epoch 83/1000\n",
      "29/29 [==============================] - 8s 285ms/step - loss: 0.1515 - accuracy: 0.2338\n",
      "Epoch 84/1000\n",
      "29/29 [==============================] - 8s 286ms/step - loss: 0.1492 - accuracy: 0.2058\n",
      "Epoch 85/1000\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.1469 - accuracy: 0.2317\n",
      "Epoch 86/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.1446 - accuracy: 0.2155\n",
      "Epoch 87/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.1424 - accuracy: 0.2144\n",
      "Epoch 88/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.1402 - accuracy: 0.2198\n",
      "Epoch 89/1000\n",
      "29/29 [==============================] - 9s 323ms/step - loss: 0.1381 - accuracy: 0.2231\n",
      "Epoch 90/1000\n",
      "29/29 [==============================] - 9s 304ms/step - loss: 0.1360 - accuracy: 0.2177\n",
      "Epoch 91/1000\n",
      "29/29 [==============================] - 10s 338ms/step - loss: 0.1339 - accuracy: 0.2209\n",
      "Epoch 92/1000\n",
      "29/29 [==============================] - 9s 326ms/step - loss: 0.1319 - accuracy: 0.2209\n",
      "Epoch 93/1000\n",
      "29/29 [==============================] - 9s 304ms/step - loss: 0.1299 - accuracy: 0.2144\n",
      "Epoch 94/1000\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.1280 - accuracy: 0.2198\n",
      "Epoch 95/1000\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.1260 - accuracy: 0.2123\n",
      "Epoch 96/1000\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.1242 - accuracy: 0.2295\n",
      "Epoch 97/1000\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.1222 - accuracy: 0.2155\n",
      "Epoch 98/1000\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.1205 - accuracy: 0.2166\n",
      "Epoch 99/1000\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.1188 - accuracy: 0.2177\n",
      "Epoch 100/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.1170 - accuracy: 0.2220\n",
      "Epoch 101/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.1153 - accuracy: 0.2274\n",
      "Epoch 102/1000\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.1135 - accuracy: 0.2177\n",
      "Epoch 103/1000\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.1119 - accuracy: 0.2166\n",
      "Epoch 104/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.1103 - accuracy: 0.2209\n",
      "Epoch 105/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.1086 - accuracy: 0.2112\n",
      "Epoch 106/1000\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.1071 - accuracy: 0.2295\n",
      "Epoch 107/1000\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.1056 - accuracy: 0.2252\n",
      "Epoch 108/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.1040 - accuracy: 0.2166\n",
      "Epoch 109/1000\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.1026 - accuracy: 0.2123\n",
      "Epoch 110/1000\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.1011 - accuracy: 0.2317\n",
      "Epoch 111/1000\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.0997 - accuracy: 0.2091\n",
      "Epoch 112/1000\n",
      "29/29 [==============================] - 11s 375ms/step - loss: 0.0983 - accuracy: 0.2241\n",
      "Epoch 113/1000\n",
      "29/29 [==============================] - 10s 336ms/step - loss: 0.0968 - accuracy: 0.2166\n",
      "Epoch 114/1000\n",
      "29/29 [==============================] - 14s 480ms/step - loss: 0.0955 - accuracy: 0.2155\n",
      "Epoch 115/1000\n",
      "29/29 [==============================] - 12s 431ms/step - loss: 0.0941 - accuracy: 0.2317\n",
      "Epoch 116/1000\n",
      "29/29 [==============================] - 14s 475ms/step - loss: 0.0928 - accuracy: 0.2209\n",
      "Epoch 117/1000\n",
      "29/29 [==============================] - 15s 512ms/step - loss: 0.0915 - accuracy: 0.2123\n",
      "Epoch 118/1000\n",
      "29/29 [==============================] - 15s 501ms/step - loss: 0.0903 - accuracy: 0.2198\n",
      "Epoch 119/1000\n",
      "29/29 [==============================] - 15s 515ms/step - loss: 0.0890 - accuracy: 0.2231\n",
      "Epoch 120/1000\n",
      "29/29 [==============================] - 16s 553ms/step - loss: 0.0878 - accuracy: 0.2220\n",
      "Epoch 121/1000\n",
      "29/29 [==============================] - 15s 525ms/step - loss: 0.0866 - accuracy: 0.2209\n",
      "Epoch 122/1000\n",
      "29/29 [==============================] - 15s 504ms/step - loss: 0.0854 - accuracy: 0.2166\n",
      "Epoch 123/1000\n",
      "29/29 [==============================] - 15s 511ms/step - loss: 0.0842 - accuracy: 0.2155\n",
      "Epoch 124/1000\n",
      "29/29 [==============================] - 14s 500ms/step - loss: 0.0831 - accuracy: 0.2284\n",
      "Epoch 125/1000\n",
      "29/29 [==============================] - 15s 507ms/step - loss: 0.0819 - accuracy: 0.2231\n",
      "Epoch 126/1000\n",
      "29/29 [==============================] - 15s 507ms/step - loss: 0.0808 - accuracy: 0.2188\n",
      "Epoch 127/1000\n",
      "29/29 [==============================] - 15s 501ms/step - loss: 0.0797 - accuracy: 0.2188\n",
      "Epoch 128/1000\n",
      "29/29 [==============================] - 15s 503ms/step - loss: 0.0786 - accuracy: 0.2123\n",
      "Epoch 129/1000\n",
      "29/29 [==============================] - 15s 510ms/step - loss: 0.0776 - accuracy: 0.2338\n",
      "Epoch 130/1000\n",
      "29/29 [==============================] - 14s 498ms/step - loss: 0.0765 - accuracy: 0.2134\n",
      "Epoch 131/1000\n",
      "29/29 [==============================] - 15s 525ms/step - loss: 0.0755 - accuracy: 0.2231\n",
      "Epoch 132/1000\n",
      "29/29 [==============================] - 14s 497ms/step - loss: 0.0745 - accuracy: 0.2317\n",
      "Epoch 133/1000\n",
      "29/29 [==============================] - 15s 511ms/step - loss: 0.0735 - accuracy: 0.2037\n",
      "Epoch 134/1000\n",
      "29/29 [==============================] - 15s 517ms/step - loss: 0.0725 - accuracy: 0.2188\n",
      "Epoch 135/1000\n",
      "29/29 [==============================] - 15s 503ms/step - loss: 0.0715 - accuracy: 0.2371\n",
      "Epoch 136/1000\n",
      "29/29 [==============================] - 15s 507ms/step - loss: 0.0706 - accuracy: 0.2123\n",
      "Epoch 137/1000\n",
      "29/29 [==============================] - 14s 499ms/step - loss: 0.0697 - accuracy: 0.2209\n",
      "Epoch 138/1000\n",
      "29/29 [==============================] - 15s 504ms/step - loss: 0.0687 - accuracy: 0.2155\n",
      "Epoch 139/1000\n",
      "29/29 [==============================] - 15s 507ms/step - loss: 0.0678 - accuracy: 0.2252\n",
      "Epoch 140/1000\n",
      "29/29 [==============================] - 15s 506ms/step - loss: 0.0669 - accuracy: 0.2274\n",
      "Epoch 141/1000\n",
      "29/29 [==============================] - 17s 573ms/step - loss: 0.0661 - accuracy: 0.2231\n",
      "Epoch 142/1000\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.0652 - accuracy: 0.2123\n",
      "Epoch 143/1000\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.0643 - accuracy: 0.2177\n",
      "Epoch 144/1000\n",
      "29/29 [==============================] - 15s 508ms/step - loss: 0.0635 - accuracy: 0.2295\n",
      "Epoch 145/1000\n",
      "29/29 [==============================] - 15s 510ms/step - loss: 0.0627 - accuracy: 0.2101\n",
      "Epoch 146/1000\n",
      "29/29 [==============================] - 15s 510ms/step - loss: 0.0619 - accuracy: 0.2295\n",
      "Epoch 147/1000\n",
      "29/29 [==============================] - 15s 515ms/step - loss: 0.0611 - accuracy: 0.2144\n",
      "Epoch 148/1000\n",
      "29/29 [==============================] - 15s 510ms/step - loss: 0.0603 - accuracy: 0.2198\n",
      "Epoch 149/1000\n",
      "29/29 [==============================] - 15s 510ms/step - loss: 0.0595 - accuracy: 0.2209\n",
      "Epoch 150/1000\n",
      "29/29 [==============================] - 15s 524ms/step - loss: 0.0588 - accuracy: 0.2209\n",
      "Epoch 151/1000\n",
      "29/29 [==============================] - 15s 517ms/step - loss: 0.0580 - accuracy: 0.2198\n",
      "Epoch 152/1000\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.0573 - accuracy: 0.2231\n",
      "Epoch 153/1000\n",
      "29/29 [==============================] - 15s 515ms/step - loss: 0.0565 - accuracy: 0.2209\n",
      "Epoch 154/1000\n",
      "29/29 [==============================] - 15s 521ms/step - loss: 0.0558 - accuracy: 0.2198\n",
      "Epoch 155/1000\n",
      "29/29 [==============================] - 15s 518ms/step - loss: 0.0551 - accuracy: 0.2231\n",
      "Epoch 156/1000\n",
      "29/29 [==============================] - 15s 514ms/step - loss: 0.0544 - accuracy: 0.2134\n",
      "Epoch 157/1000\n",
      "29/29 [==============================] - 15s 522ms/step - loss: 0.0537 - accuracy: 0.2274\n",
      "Epoch 158/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 15s 514ms/step - loss: 0.0530 - accuracy: 0.2155\n",
      "Epoch 159/1000\n",
      "29/29 [==============================] - 15s 507ms/step - loss: 0.0523 - accuracy: 0.2198\n",
      "Epoch 160/1000\n",
      "29/29 [==============================] - 14s 496ms/step - loss: 0.0518 - accuracy: 0.2231\n",
      "Epoch 161/1000\n",
      "29/29 [==============================] - 17s 578ms/step - loss: 0.0511 - accuracy: 0.2047\n",
      "Epoch 162/1000\n",
      "29/29 [==============================] - 15s 529ms/step - loss: 0.0504 - accuracy: 0.2381\n",
      "Epoch 163/1000\n",
      "29/29 [==============================] - 14s 494ms/step - loss: 0.0498 - accuracy: 0.2252\n",
      "Epoch 164/1000\n",
      "29/29 [==============================] - 14s 499ms/step - loss: 0.0492 - accuracy: 0.2123\n",
      "Epoch 165/1000\n",
      "29/29 [==============================] - 15s 505ms/step - loss: 0.0486 - accuracy: 0.2198\n",
      "Epoch 166/1000\n",
      "29/29 [==============================] - 15s 504ms/step - loss: 0.0480 - accuracy: 0.2295\n",
      "Epoch 167/1000\n",
      "29/29 [==============================] - 14s 495ms/step - loss: 0.0474 - accuracy: 0.2166\n",
      "Epoch 168/1000\n",
      "29/29 [==============================] - 14s 500ms/step - loss: 0.0468 - accuracy: 0.2166\n",
      "Epoch 169/1000\n",
      "29/29 [==============================] - 15s 502ms/step - loss: 0.0462 - accuracy: 0.2306\n",
      "Epoch 170/1000\n",
      "29/29 [==============================] - 15s 516ms/step - loss: 0.0457 - accuracy: 0.1983\n",
      "Epoch 171/1000\n",
      "29/29 [==============================] - 14s 498ms/step - loss: 0.0451 - accuracy: 0.2209\n",
      "Epoch 172/1000\n",
      "29/29 [==============================] - 15s 501ms/step - loss: 0.0446 - accuracy: 0.2198\n",
      "Epoch 173/1000\n",
      "29/29 [==============================] - 15s 518ms/step - loss: 0.0440 - accuracy: 0.2371\n",
      "Epoch 174/1000\n",
      "29/29 [==============================] - 15s 504ms/step - loss: 0.0435 - accuracy: 0.2220\n",
      "Epoch 175/1000\n",
      "29/29 [==============================] - 14s 498ms/step - loss: 0.0430 - accuracy: 0.2134\n",
      "Epoch 176/1000\n",
      "29/29 [==============================] - 14s 499ms/step - loss: 0.0424 - accuracy: 0.2155\n",
      "Epoch 177/1000\n",
      "29/29 [==============================] - 15s 501ms/step - loss: 0.0419 - accuracy: 0.2263\n",
      "Epoch 178/1000\n",
      "29/29 [==============================] - 15s 507ms/step - loss: 0.0415 - accuracy: 0.2209\n",
      "Epoch 179/1000\n",
      "29/29 [==============================] - 15s 512ms/step - loss: 0.0409 - accuracy: 0.2188\n",
      "Epoch 180/1000\n",
      "29/29 [==============================] - 15s 501ms/step - loss: 0.0405 - accuracy: 0.2220\n",
      "Epoch 181/1000\n",
      "29/29 [==============================] - 15s 512ms/step - loss: 0.0400 - accuracy: 0.2198\n",
      "Epoch 182/1000\n",
      "29/29 [==============================] - 16s 541ms/step - loss: 0.0395 - accuracy: 0.2166\n",
      "Epoch 183/1000\n",
      "29/29 [==============================] - 15s 530ms/step - loss: 0.0391 - accuracy: 0.2241\n",
      "Epoch 184/1000\n",
      "29/29 [==============================] - 15s 500ms/step - loss: 0.0385 - accuracy: 0.2155\n",
      "Epoch 185/1000\n",
      "29/29 [==============================] - 15s 504ms/step - loss: 0.0381 - accuracy: 0.2317\n",
      "Epoch 186/1000\n",
      "29/29 [==============================] - 14s 496ms/step - loss: 0.0377 - accuracy: 0.2134\n",
      "Epoch 187/1000\n",
      "29/29 [==============================] - 14s 493ms/step - loss: 0.0372 - accuracy: 0.2177\n",
      "Epoch 188/1000\n",
      "29/29 [==============================] - 14s 497ms/step - loss: 0.0368 - accuracy: 0.2209\n",
      "Epoch 189/1000\n",
      "29/29 [==============================] - 15s 511ms/step - loss: 0.0363 - accuracy: 0.2263\n",
      "Epoch 190/1000\n",
      "29/29 [==============================] - 15s 508ms/step - loss: 0.0360 - accuracy: 0.2123\n",
      "Epoch 191/1000\n",
      "29/29 [==============================] - 15s 502ms/step - loss: 0.0354 - accuracy: 0.2263\n",
      "Epoch 192/1000\n",
      "29/29 [==============================] - 15s 506ms/step - loss: 0.0351 - accuracy: 0.2295\n",
      "Epoch 193/1000\n",
      "29/29 [==============================] - 15s 506ms/step - loss: 0.0347 - accuracy: 0.2026\n",
      "Epoch 194/1000\n",
      "29/29 [==============================] - 15s 502ms/step - loss: 0.0343 - accuracy: 0.2263\n",
      "Epoch 195/1000\n",
      "29/29 [==============================] - 14s 499ms/step - loss: 0.0339 - accuracy: 0.2188\n",
      "Epoch 196/1000\n",
      "29/29 [==============================] - 14s 500ms/step - loss: 0.0335 - accuracy: 0.2274\n",
      "Epoch 197/1000\n",
      "29/29 [==============================] - 15s 509ms/step - loss: 0.0331 - accuracy: 0.2188\n",
      "Epoch 198/1000\n",
      "29/29 [==============================] - 14s 499ms/step - loss: 0.0327 - accuracy: 0.2263\n",
      "Epoch 199/1000\n",
      "29/29 [==============================] - 15s 503ms/step - loss: 0.0324 - accuracy: 0.2112\n",
      "Epoch 200/1000\n",
      "29/29 [==============================] - 14s 493ms/step - loss: 0.0319 - accuracy: 0.2274\n",
      "Epoch 201/1000\n",
      "29/29 [==============================] - 15s 510ms/step - loss: 0.0316 - accuracy: 0.2231\n",
      "Epoch 202/1000\n",
      "29/29 [==============================] - 15s 501ms/step - loss: 0.0313 - accuracy: 0.2112\n",
      "Epoch 203/1000\n",
      "29/29 [==============================] - 16s 552ms/step - loss: 0.0309 - accuracy: 0.2284\n",
      "Epoch 204/1000\n",
      "29/29 [==============================] - 17s 581ms/step - loss: 0.0306 - accuracy: 0.2198\n",
      "Epoch 205/1000\n",
      "29/29 [==============================] - 752s 26s/step - loss: 0.0302 - accuracy: 0.2231\n",
      "Epoch 206/1000\n",
      "29/29 [==============================] - 11s 395ms/step - loss: 0.0299 - accuracy: 0.2144\n",
      "Epoch 207/1000\n",
      "29/29 [==============================] - 11s 363ms/step - loss: 0.0296 - accuracy: 0.2134\n",
      "Epoch 208/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.0292 - accuracy: 0.2209\n",
      "Epoch 209/1000\n",
      "29/29 [==============================] - 11s 386ms/step - loss: 0.0289 - accuracy: 0.2263\n",
      "Epoch 210/1000\n",
      "29/29 [==============================] - 11s 379ms/step - loss: 0.0286 - accuracy: 0.2209\n",
      "Epoch 211/1000\n",
      "29/29 [==============================] - 10s 356ms/step - loss: 0.0283 - accuracy: 0.2155\n",
      "Epoch 212/1000\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.0279 - accuracy: 0.2241\n",
      "Epoch 213/1000\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.0276 - accuracy: 0.2241\n",
      "Epoch 214/1000\n",
      "29/29 [==============================] - 8s 293ms/step - loss: 0.0273 - accuracy: 0.2198\n",
      "Epoch 215/1000\n",
      "29/29 [==============================] - 9s 319ms/step - loss: 0.0270 - accuracy: 0.2177\n",
      "Epoch 216/1000\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.0267 - accuracy: 0.2263\n",
      "Epoch 217/1000\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.0264 - accuracy: 0.2155\n",
      "Epoch 218/1000\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.0262 - accuracy: 0.2220\n",
      "Epoch 219/1000\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.0258 - accuracy: 0.2274\n",
      "Epoch 220/1000\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.0256 - accuracy: 0.2080\n",
      "Epoch 221/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.0253 - accuracy: 0.2166\n",
      "Epoch 222/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0250 - accuracy: 0.2198\n",
      "Epoch 223/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.0247 - accuracy: 0.2284\n",
      "Epoch 224/1000\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.0245 - accuracy: 0.2144\n",
      "Epoch 225/1000\n",
      "29/29 [==============================] - 10s 332ms/step - loss: 0.0242 - accuracy: 0.2155\n",
      "Epoch 226/1000\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.0239 - accuracy: 0.2263\n",
      "Epoch 227/1000\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.0237 - accuracy: 0.2295\n",
      "Epoch 228/1000\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.0235 - accuracy: 0.2069\n",
      "Epoch 229/1000\n",
      "29/29 [==============================] - 9s 304ms/step - loss: 0.0232 - accuracy: 0.2381\n",
      "Epoch 230/1000\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.0229 - accuracy: 0.2188\n",
      "Epoch 231/1000\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.0227 - accuracy: 0.2112\n",
      "Epoch 232/1000\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.0225 - accuracy: 0.2241\n",
      "Epoch 233/1000\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.0222 - accuracy: 0.2101\n",
      "Epoch 234/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.0220 - accuracy: 0.2284\n",
      "Epoch 235/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0218 - accuracy: 0.2209\n",
      "Epoch 236/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 9s 296ms/step - loss: 0.0215 - accuracy: 0.2274\n",
      "Epoch 237/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.0213 - accuracy: 0.2220\n",
      "Epoch 238/1000\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.0211 - accuracy: 0.2144\n",
      "Epoch 239/1000\n",
      "29/29 [==============================] - 8s 293ms/step - loss: 0.0209 - accuracy: 0.2198\n",
      "Epoch 240/1000\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.0207 - accuracy: 0.2220\n",
      "Epoch 241/1000\n",
      "29/29 [==============================] - 8s 287ms/step - loss: 0.0205 - accuracy: 0.2209\n",
      "Epoch 242/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.0203 - accuracy: 0.2241\n",
      "Epoch 243/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.0200 - accuracy: 0.2188\n",
      "Epoch 244/1000\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.0198 - accuracy: 0.2144\n",
      "Epoch 245/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.0196 - accuracy: 0.2274\n",
      "Epoch 246/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.0194 - accuracy: 0.2155\n",
      "Epoch 247/1000\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.0193 - accuracy: 0.2231\n",
      "Epoch 248/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0191 - accuracy: 0.2155\n",
      "Epoch 249/1000\n",
      "29/29 [==============================] - 251s 9s/step - loss: 0.0188 - accuracy: 0.2284\n",
      "Epoch 250/1000\n",
      "29/29 [==============================] - 10s 350ms/step - loss: 0.0187 - accuracy: 0.2123\n",
      "Epoch 251/1000\n",
      "29/29 [==============================] - 9s 322ms/step - loss: 0.0185 - accuracy: 0.2338\n",
      "Epoch 252/1000\n",
      "29/29 [==============================] - 9s 323ms/step - loss: 0.0182 - accuracy: 0.2069\n",
      "Epoch 253/1000\n",
      "29/29 [==============================] - 8s 284ms/step - loss: 0.0182 - accuracy: 0.2241\n",
      "Epoch 254/1000\n",
      "29/29 [==============================] - 8s 287ms/step - loss: 0.0179 - accuracy: 0.2306\n",
      "Epoch 255/1000\n",
      "29/29 [==============================] - 197s 7s/step - loss: 0.0177 - accuracy: 0.2166\n",
      "Epoch 256/1000\n",
      "29/29 [==============================] - 10s 344ms/step - loss: 0.0176 - accuracy: 0.2155\n",
      "Epoch 257/1000\n",
      "29/29 [==============================] - 10s 330ms/step - loss: 0.0175 - accuracy: 0.2209\n",
      "Epoch 258/1000\n",
      "29/29 [==============================] - 10s 344ms/step - loss: 0.0172 - accuracy: 0.2155\n",
      "Epoch 259/1000\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.0171 - accuracy: 0.2263\n",
      "Epoch 260/1000\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.0169 - accuracy: 0.2252\n",
      "Epoch 261/1000\n",
      "29/29 [==============================] - 10s 336ms/step - loss: 0.0168 - accuracy: 0.2080\n",
      "Epoch 262/1000\n",
      "29/29 [==============================] - 10s 343ms/step - loss: 0.0166 - accuracy: 0.2231\n",
      "Epoch 263/1000\n",
      "29/29 [==============================] - 10s 358ms/step - loss: 0.0164 - accuracy: 0.2177\n",
      "Epoch 264/1000\n",
      "29/29 [==============================] - 10s 330ms/step - loss: 0.0163 - accuracy: 0.2317\n",
      "Epoch 265/1000\n",
      "29/29 [==============================] - 10s 343ms/step - loss: 0.0161 - accuracy: 0.2155\n",
      "Epoch 266/1000\n",
      "29/29 [==============================] - 9s 326ms/step - loss: 0.0160 - accuracy: 0.2263\n",
      "Epoch 267/1000\n",
      "29/29 [==============================] - 9s 306ms/step - loss: 0.0158 - accuracy: 0.2188\n",
      "Epoch 268/1000\n",
      "29/29 [==============================] - 9s 326ms/step - loss: 0.0157 - accuracy: 0.2123\n",
      "Epoch 269/1000\n",
      "29/29 [==============================] - 11s 369ms/step - loss: 0.0155 - accuracy: 0.2231\n",
      "Epoch 270/1000\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.0153 - accuracy: 0.2231\n",
      "Epoch 271/1000\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.0152 - accuracy: 0.2188\n",
      "Epoch 272/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0151 - accuracy: 0.2220\n",
      "Epoch 273/1000\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.0149 - accuracy: 0.2188\n",
      "Epoch 274/1000\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.0148 - accuracy: 0.2220\n",
      "Epoch 275/1000\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.0147 - accuracy: 0.2220\n",
      "Epoch 276/1000\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.0144 - accuracy: 0.2188\n",
      "Epoch 277/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0144 - accuracy: 0.2231\n",
      "Epoch 278/1000\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.0142 - accuracy: 0.2209\n",
      "Epoch 279/1000\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.0141 - accuracy: 0.2220\n",
      "Epoch 280/1000\n",
      "29/29 [==============================] - 10s 331ms/step - loss: 0.0141 - accuracy: 0.2241\n",
      "Epoch 281/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0139 - accuracy: 0.2144\n",
      "Epoch 282/1000\n",
      "29/29 [==============================] - 10s 329ms/step - loss: 0.0138 - accuracy: 0.2155\n",
      "Epoch 283/1000\n",
      "29/29 [==============================] - 9s 304ms/step - loss: 0.0136 - accuracy: 0.2317\n",
      "Epoch 284/1000\n",
      "29/29 [==============================] - 9s 326ms/step - loss: 0.0134 - accuracy: 0.2166\n",
      "Epoch 285/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.0134 - accuracy: 0.2188\n",
      "Epoch 286/1000\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.0133 - accuracy: 0.2166\n",
      "Epoch 287/1000\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.0131 - accuracy: 0.2263\n",
      "Epoch 288/1000\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.0130 - accuracy: 0.2220\n",
      "Epoch 289/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.0129 - accuracy: 0.2155\n",
      "Epoch 290/1000\n",
      "29/29 [==============================] - 8s 293ms/step - loss: 0.0128 - accuracy: 0.2134\n",
      "Epoch 291/1000\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.0127 - accuracy: 0.2241\n",
      "Epoch 292/1000\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.0126 - accuracy: 0.2252\n",
      "Epoch 293/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.0124 - accuracy: 0.2155\n",
      "Epoch 294/1000\n",
      "29/29 [==============================] - 8s 291ms/step - loss: 0.0124 - accuracy: 0.2295\n",
      "Epoch 295/1000\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.0123 - accuracy: 0.2177\n",
      "Epoch 296/1000\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.0122 - accuracy: 0.2166\n",
      "Epoch 297/1000\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.0120 - accuracy: 0.2274\n",
      "Epoch 298/1000\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.0120 - accuracy: 0.2112\n",
      "Epoch 299/1000\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.0118 - accuracy: 0.2209\n",
      "Epoch 300/1000\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.0117 - accuracy: 0.2209\n",
      "Epoch 301/1000\n",
      "29/29 [==============================] - 10s 344ms/step - loss: 0.0116 - accuracy: 0.2220\n",
      "Epoch 302/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.0116 - accuracy: 0.2220\n",
      "Epoch 303/1000\n",
      "29/29 [==============================] - 16s 540ms/step - loss: 0.0115 - accuracy: 0.2134\n",
      "Epoch 304/1000\n",
      "29/29 [==============================] - 10s 356ms/step - loss: 0.0113 - accuracy: 0.2338\n",
      "Epoch 305/1000\n",
      "29/29 [==============================] - 10s 330ms/step - loss: 0.0113 - accuracy: 0.2166\n",
      "Epoch 306/1000\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.0112 - accuracy: 0.2220\n",
      "Epoch 307/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0111 - accuracy: 0.2058\n",
      "Epoch 308/1000\n",
      "29/29 [==============================] - 9s 325ms/step - loss: 0.0111 - accuracy: 0.2188\n",
      "Epoch 309/1000\n",
      "29/29 [==============================] - 9s 318ms/step - loss: 0.0109 - accuracy: 0.2328\n",
      "Epoch 310/1000\n",
      "29/29 [==============================] - 9s 307ms/step - loss: 0.0108 - accuracy: 0.2295\n",
      "Epoch 311/1000\n",
      "29/29 [==============================] - 8s 293ms/step - loss: 0.0107 - accuracy: 0.2101\n",
      "Epoch 312/1000\n",
      "29/29 [==============================] - 431s 15s/step - loss: 0.0107 - accuracy: 0.2101\n",
      "Epoch 313/1000\n",
      "29/29 [==============================] - 11s 381ms/step - loss: 0.0106 - accuracy: 0.2446\n",
      "Epoch 314/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 10s 343ms/step - loss: 0.0105 - accuracy: 0.2080\n",
      "Epoch 315/1000\n",
      "29/29 [==============================] - 9s 309ms/step - loss: 0.0104 - accuracy: 0.2166\n",
      "Epoch 316/1000\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.0102 - accuracy: 0.2284\n",
      "Epoch 317/1000\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.0103 - accuracy: 0.2263\n",
      "Epoch 318/1000\n",
      "29/29 [==============================] - 10s 354ms/step - loss: 0.0101 - accuracy: 0.2047\n",
      "Epoch 319/1000\n",
      "29/29 [==============================] - 10s 332ms/step - loss: 0.0101 - accuracy: 0.2166\n",
      "Epoch 320/1000\n",
      "29/29 [==============================] - 9s 326ms/step - loss: 0.0100 - accuracy: 0.2306\n",
      "Epoch 321/1000\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.0100 - accuracy: 0.2155\n",
      "Epoch 322/1000\n",
      "29/29 [==============================] - 11s 366ms/step - loss: 0.0098 - accuracy: 0.2371\n",
      "Epoch 323/1000\n",
      "29/29 [==============================] - 10s 349ms/step - loss: 0.0098 - accuracy: 0.2080\n",
      "Epoch 324/1000\n",
      "29/29 [==============================] - 9s 320ms/step - loss: 0.0097 - accuracy: 0.2198\n",
      "Epoch 325/1000\n",
      "29/29 [==============================] - 9s 328ms/step - loss: 0.0096 - accuracy: 0.2274\n",
      "Epoch 326/1000\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.0095 - accuracy: 0.2047\n",
      "Epoch 327/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.0095 - accuracy: 0.2306\n",
      "Epoch 328/1000\n",
      "29/29 [==============================] - 8s 284ms/step - loss: 0.0094 - accuracy: 0.2198\n",
      "Epoch 329/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.0094 - accuracy: 0.2198\n",
      "Epoch 330/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0093 - accuracy: 0.2166\n",
      "Epoch 331/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.0092 - accuracy: 0.2274\n",
      "Epoch 332/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0091 - accuracy: 0.2144\n",
      "Epoch 333/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.0091 - accuracy: 0.2241\n",
      "Epoch 334/1000\n",
      "29/29 [==============================] - 8s 287ms/step - loss: 0.0090 - accuracy: 0.2177\n",
      "Epoch 335/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.0090 - accuracy: 0.2166\n",
      "Epoch 336/1000\n",
      "29/29 [==============================] - 8s 280ms/step - loss: 0.0088 - accuracy: 0.2241\n",
      "Epoch 337/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.0088 - accuracy: 0.2231\n",
      "Epoch 338/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.0088 - accuracy: 0.2188\n",
      "Epoch 339/1000\n",
      "29/29 [==============================] - 8s 281ms/step - loss: 0.0087 - accuracy: 0.2284\n",
      "Epoch 340/1000\n",
      "29/29 [==============================] - 8s 282ms/step - loss: 0.0086 - accuracy: 0.2263\n",
      "Epoch 341/1000\n",
      "29/29 [==============================] - 8s 284ms/step - loss: 0.0086 - accuracy: 0.2134\n",
      "Epoch 342/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.0085 - accuracy: 0.2166\n",
      "Epoch 343/1000\n",
      "29/29 [==============================] - 8s 280ms/step - loss: 0.0084 - accuracy: 0.2306\n",
      "Epoch 344/1000\n",
      "29/29 [==============================] - 8s 282ms/step - loss: 0.0084 - accuracy: 0.2263\n",
      "Epoch 345/1000\n",
      "29/29 [==============================] - 8s 284ms/step - loss: 0.0084 - accuracy: 0.2037\n",
      "Epoch 346/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.0083 - accuracy: 0.2284\n",
      "Epoch 347/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.0083 - accuracy: 0.2144\n",
      "Epoch 348/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.0082 - accuracy: 0.2080\n",
      "Epoch 349/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.0081 - accuracy: 0.2349\n",
      "Epoch 350/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.0081 - accuracy: 0.2134\n",
      "Epoch 351/1000\n",
      "29/29 [==============================] - 8s 283ms/step - loss: 0.0080 - accuracy: 0.2177\n",
      "Epoch 352/1000\n",
      "29/29 [==============================] - 8s 284ms/step - loss: 0.0080 - accuracy: 0.2220\n",
      "Epoch 353/1000\n",
      "29/29 [==============================] - 8s 280ms/step - loss: 0.0079 - accuracy: 0.2231\n",
      "Epoch 354/1000\n",
      "29/29 [==============================] - 8s 284ms/step - loss: 0.0078 - accuracy: 0.2295\n",
      "Epoch 355/1000\n",
      "29/29 [==============================] - 8s 282ms/step - loss: 0.0079 - accuracy: 0.2091\n",
      "Epoch 356/1000\n",
      "29/29 [==============================] - 8s 281ms/step - loss: 0.0078 - accuracy: 0.2284\n",
      "Epoch 357/1000\n",
      "29/29 [==============================] - 9s 304ms/step - loss: 0.0077 - accuracy: 0.2101\n",
      "Epoch 358/1000\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.0076 - accuracy: 0.2306\n",
      "Epoch 359/1000\n",
      "29/29 [==============================] - 8s 293ms/step - loss: 0.0077 - accuracy: 0.2177\n",
      "Epoch 360/1000\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.0076 - accuracy: 0.2198\n",
      "Epoch 361/1000\n",
      "29/29 [==============================] - 13s 442ms/step - loss: 0.0075 - accuracy: 0.2188\n",
      "Epoch 362/1000\n",
      "29/29 [==============================] - 9s 316ms/step - loss: 0.0075 - accuracy: 0.2209\n",
      "Epoch 363/1000\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.0074 - accuracy: 0.2220\n",
      "Epoch 364/1000\n",
      "29/29 [==============================] - 8s 291ms/step - loss: 0.0074 - accuracy: 0.2209\n",
      "Epoch 365/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0073 - accuracy: 0.2231\n",
      "Epoch 366/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.0073 - accuracy: 0.2166\n",
      "Epoch 367/1000\n",
      "29/29 [==============================] - 8s 284ms/step - loss: 0.0073 - accuracy: 0.2177\n",
      "Epoch 368/1000\n",
      "29/29 [==============================] - 9s 293ms/step - loss: 0.0073 - accuracy: 0.2144\n",
      "Epoch 369/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.0071 - accuracy: 0.2209\n",
      "Epoch 370/1000\n",
      "29/29 [==============================] - 8s 281ms/step - loss: 0.0072 - accuracy: 0.2381\n",
      "Epoch 371/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.0071 - accuracy: 0.2101\n",
      "Epoch 372/1000\n",
      "29/29 [==============================] - 9s 326ms/step - loss: 0.0070 - accuracy: 0.2166\n",
      "Epoch 373/1000\n",
      "29/29 [==============================] - 8s 285ms/step - loss: 0.0070 - accuracy: 0.2134\n",
      "Epoch 374/1000\n",
      "29/29 [==============================] - 8s 285ms/step - loss: 0.0070 - accuracy: 0.2252\n",
      "Epoch 375/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.0069 - accuracy: 0.2252\n",
      "Epoch 376/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.0068 - accuracy: 0.2263\n",
      "Epoch 377/1000\n",
      "29/29 [==============================] - 8s 282ms/step - loss: 0.0069 - accuracy: 0.2112\n",
      "Epoch 378/1000\n",
      "29/29 [==============================] - 8s 283ms/step - loss: 0.0068 - accuracy: 0.2328\n",
      "Epoch 379/1000\n",
      "29/29 [==============================] - 8s 284ms/step - loss: 0.0069 - accuracy: 0.2069\n",
      "Epoch 380/1000\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.0068 - accuracy: 0.2220\n",
      "Epoch 381/1000\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.0067 - accuracy: 0.2338\n",
      "Epoch 382/1000\n",
      "29/29 [==============================] - 8s 287ms/step - loss: 0.0067 - accuracy: 0.2101\n",
      "Epoch 383/1000\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.0067 - accuracy: 0.2284\n",
      "Epoch 384/1000\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.0066 - accuracy: 0.2220\n",
      "Epoch 385/1000\n",
      "29/29 [==============================] - 8s 285ms/step - loss: 0.0066 - accuracy: 0.2252\n",
      "Epoch 386/1000\n",
      "29/29 [==============================] - 8s 280ms/step - loss: 0.0065 - accuracy: 0.2188\n",
      "Epoch 387/1000\n",
      "29/29 [==============================] - 8s 287ms/step - loss: 0.0065 - accuracy: 0.2220\n",
      "Epoch 388/1000\n",
      "29/29 [==============================] - 8s 285ms/step - loss: 0.0065 - accuracy: 0.2166\n",
      "Epoch 389/1000\n",
      "29/29 [==============================] - 8s 284ms/step - loss: 0.0064 - accuracy: 0.2231\n",
      "Epoch 390/1000\n",
      "29/29 [==============================] - 8s 291ms/step - loss: 0.0064 - accuracy: 0.2231\n",
      "Epoch 391/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.0064 - accuracy: 0.2198\n",
      "Epoch 392/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 8s 284ms/step - loss: 0.0063 - accuracy: 0.2252\n",
      "Epoch 393/1000\n",
      "29/29 [==============================] - 8s 279ms/step - loss: 0.0063 - accuracy: 0.2252\n",
      "Epoch 394/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.0063 - accuracy: 0.2134\n",
      "Epoch 395/1000\n",
      "29/29 [==============================] - 8s 284ms/step - loss: 0.0063 - accuracy: 0.2295\n",
      "Epoch 396/1000\n",
      "29/29 [==============================] - 8s 286ms/step - loss: 0.0062 - accuracy: 0.2123\n",
      "Epoch 397/1000\n",
      "29/29 [==============================] - 10s 359ms/step - loss: 0.0061 - accuracy: 0.2349\n",
      "Epoch 398/1000\n",
      "29/29 [==============================] - 10s 354ms/step - loss: 0.0062 - accuracy: 0.2101\n",
      "Epoch 399/1000\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.0062 - accuracy: 0.2220\n",
      "Epoch 400/1000\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.0061 - accuracy: 0.2177\n",
      "Epoch 401/1000\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 0.0061 - accuracy: 0.2209\n",
      "Epoch 402/1000\n",
      "29/29 [==============================] - 11s 379ms/step - loss: 0.0060 - accuracy: 0.2295\n",
      "Epoch 403/1000\n",
      "29/29 [==============================] - 14s 498ms/step - loss: 0.0060 - accuracy: 0.2123\n",
      "Epoch 404/1000\n",
      "29/29 [==============================] - 14s 487ms/step - loss: 0.0060 - accuracy: 0.2306\n",
      "Epoch 405/1000\n",
      "29/29 [==============================] - 14s 496ms/step - loss: 0.0060 - accuracy: 0.2166\n",
      "Epoch 406/1000\n",
      "29/29 [==============================] - 14s 483ms/step - loss: 0.0059 - accuracy: 0.2317\n",
      "Epoch 407/1000\n",
      "29/29 [==============================] - 15s 507ms/step - loss: 0.0059 - accuracy: 0.2091\n",
      "Epoch 408/1000\n",
      "29/29 [==============================] - 14s 492ms/step - loss: 0.0059 - accuracy: 0.2188\n",
      "Epoch 409/1000\n",
      "29/29 [==============================] - 15s 503ms/step - loss: 0.0058 - accuracy: 0.2414\n",
      "Epoch 410/1000\n",
      "29/29 [==============================] - 14s 490ms/step - loss: 0.0059 - accuracy: 0.2037\n",
      "Epoch 411/1000\n",
      "29/29 [==============================] - 15s 529ms/step - loss: 0.0058 - accuracy: 0.2263\n",
      "Epoch 412/1000\n",
      "29/29 [==============================] - 15s 523ms/step - loss: 0.0058 - accuracy: 0.2177\n",
      "Epoch 413/1000\n",
      "29/29 [==============================] - 15s 506ms/step - loss: 0.0058 - accuracy: 0.2317\n",
      "Epoch 414/1000\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.0057 - accuracy: 0.2112\n",
      "Epoch 415/1000\n",
      "29/29 [==============================] - 15s 507ms/step - loss: 0.0057 - accuracy: 0.2295\n",
      "Epoch 416/1000\n",
      "29/29 [==============================] - 14s 483ms/step - loss: 0.0056 - accuracy: 0.2123\n",
      "Epoch 417/1000\n",
      "29/29 [==============================] - 14s 488ms/step - loss: 0.0057 - accuracy: 0.2274\n",
      "Epoch 418/1000\n",
      "29/29 [==============================] - 14s 481ms/step - loss: 0.0057 - accuracy: 0.2231\n",
      "Epoch 419/1000\n",
      "29/29 [==============================] - 14s 490ms/step - loss: 0.0056 - accuracy: 0.2209\n",
      "Epoch 420/1000\n",
      "29/29 [==============================] - 14s 481ms/step - loss: 0.0056 - accuracy: 0.2188\n",
      "Epoch 421/1000\n",
      "29/29 [==============================] - 14s 500ms/step - loss: 0.0056 - accuracy: 0.2252\n",
      "Epoch 422/1000\n",
      "29/29 [==============================] - 14s 494ms/step - loss: 0.0055 - accuracy: 0.2144\n",
      "Epoch 423/1000\n",
      "29/29 [==============================] - 14s 483ms/step - loss: 0.0055 - accuracy: 0.2284\n",
      "Epoch 424/1000\n",
      "29/29 [==============================] - 14s 492ms/step - loss: 0.0055 - accuracy: 0.2209\n",
      "Epoch 425/1000\n",
      "29/29 [==============================] - 14s 490ms/step - loss: 0.0055 - accuracy: 0.2144\n",
      "Epoch 426/1000\n",
      "29/29 [==============================] - 14s 478ms/step - loss: 0.0054 - accuracy: 0.2220\n",
      "Epoch 427/1000\n",
      "29/29 [==============================] - 14s 486ms/step - loss: 0.0055 - accuracy: 0.2220\n",
      "Epoch 428/1000\n",
      "29/29 [==============================] - 15s 504ms/step - loss: 0.0054 - accuracy: 0.2241\n",
      "Epoch 429/1000\n",
      "29/29 [==============================] - 14s 498ms/step - loss: 0.0054 - accuracy: 0.2274\n",
      "Epoch 430/1000\n",
      "29/29 [==============================] - 14s 495ms/step - loss: 0.0054 - accuracy: 0.2263\n",
      "Epoch 431/1000\n",
      "29/29 [==============================] - 14s 487ms/step - loss: 0.0054 - accuracy: 0.2328\n",
      "Epoch 432/1000\n",
      "29/29 [==============================] - 15s 504ms/step - loss: 0.0053 - accuracy: 0.2155\n",
      "Epoch 433/1000\n",
      "29/29 [==============================] - 15s 534ms/step - loss: 0.0053 - accuracy: 0.2177\n",
      "Epoch 434/1000\n",
      "29/29 [==============================] - 14s 478ms/step - loss: 0.0053 - accuracy: 0.2091\n",
      "Epoch 435/1000\n",
      "29/29 [==============================] - 14s 474ms/step - loss: 0.0053 - accuracy: 0.2360\n",
      "Epoch 436/1000\n",
      "29/29 [==============================] - 14s 499ms/step - loss: 0.0053 - accuracy: 0.2101\n",
      "Epoch 437/1000\n",
      "29/29 [==============================] - 16s 556ms/step - loss: 0.0053 - accuracy: 0.2274\n",
      "Epoch 438/1000\n",
      "29/29 [==============================] - 17s 577ms/step - loss: 0.0052 - accuracy: 0.2209\n",
      "Epoch 439/1000\n",
      "29/29 [==============================] - 17s 580ms/step - loss: 0.0053 - accuracy: 0.2241\n",
      "Epoch 440/1000\n",
      "29/29 [==============================] - 16s 542ms/step - loss: 0.0052 - accuracy: 0.2112\n",
      "Epoch 441/1000\n",
      "29/29 [==============================] - 15s 516ms/step - loss: 0.0051 - accuracy: 0.2241\n",
      "Epoch 442/1000\n",
      "29/29 [==============================] - 15s 517ms/step - loss: 0.0053 - accuracy: 0.2220\n",
      "Epoch 443/1000\n",
      "29/29 [==============================] - 15s 527ms/step - loss: 0.0051 - accuracy: 0.2144\n",
      "Epoch 444/1000\n",
      "29/29 [==============================] - 16s 559ms/step - loss: 0.0051 - accuracy: 0.2349\n",
      "Epoch 445/1000\n",
      "29/29 [==============================] - 15s 525ms/step - loss: 0.0052 - accuracy: 0.2134\n",
      "Epoch 446/1000\n",
      "29/29 [==============================] - 15s 514ms/step - loss: 0.0051 - accuracy: 0.2295\n",
      "Epoch 447/1000\n",
      "29/29 [==============================] - 15s 534ms/step - loss: 0.0051 - accuracy: 0.2155\n",
      "Epoch 448/1000\n",
      "29/29 [==============================] - 15s 527ms/step - loss: 0.0051 - accuracy: 0.2252\n",
      "Epoch 449/1000\n",
      "29/29 [==============================] - 16s 547ms/step - loss: 0.0051 - accuracy: 0.2198\n",
      "Epoch 450/1000\n",
      "29/29 [==============================] - 15s 532ms/step - loss: 0.0050 - accuracy: 0.2220\n",
      "Epoch 451/1000\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.0050 - accuracy: 0.2263\n",
      "Epoch 452/1000\n",
      "29/29 [==============================] - 16s 550ms/step - loss: 0.0050 - accuracy: 0.2177\n",
      "Epoch 453/1000\n",
      "29/29 [==============================] - 17s 590ms/step - loss: 0.0050 - accuracy: 0.2252\n",
      "Epoch 454/1000\n",
      "29/29 [==============================] - 15s 532ms/step - loss: 0.0050 - accuracy: 0.2252\n",
      "Epoch 455/1000\n",
      "29/29 [==============================] - 15s 530ms/step - loss: 0.0050 - accuracy: 0.2155\n",
      "Epoch 456/1000\n",
      "29/29 [==============================] - 15s 522ms/step - loss: 0.0049 - accuracy: 0.2252\n",
      "Epoch 457/1000\n",
      "29/29 [==============================] - 15s 523ms/step - loss: 0.0049 - accuracy: 0.2188\n",
      "Epoch 458/1000\n",
      "29/29 [==============================] - 15s 515ms/step - loss: 0.0049 - accuracy: 0.2209\n",
      "Epoch 459/1000\n",
      "29/29 [==============================] - 16s 535ms/step - loss: 0.0050 - accuracy: 0.2198\n",
      "Epoch 460/1000\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.0049 - accuracy: 0.2252\n",
      "Epoch 461/1000\n",
      "29/29 [==============================] - 16s 536ms/step - loss: 0.0049 - accuracy: 0.2231\n",
      "Epoch 462/1000\n",
      "29/29 [==============================] - 15s 528ms/step - loss: 0.0048 - accuracy: 0.2101\n",
      "Epoch 463/1000\n",
      "29/29 [==============================] - 16s 537ms/step - loss: 0.0049 - accuracy: 0.2209\n",
      "Epoch 464/1000\n",
      "29/29 [==============================] - 15s 512ms/step - loss: 0.0049 - accuracy: 0.2295\n",
      "Epoch 465/1000\n",
      "29/29 [==============================] - 18s 610ms/step - loss: 0.0047 - accuracy: 0.2306\n",
      "Epoch 466/1000\n",
      "29/29 [==============================] - 18s 611ms/step - loss: 0.0049 - accuracy: 0.2047\n",
      "Epoch 467/1000\n",
      "29/29 [==============================] - 16s 539ms/step - loss: 0.0048 - accuracy: 0.2317\n",
      "Epoch 468/1000\n",
      "29/29 [==============================] - 16s 568ms/step - loss: 0.0048 - accuracy: 0.2198\n",
      "Epoch 469/1000\n",
      "29/29 [==============================] - 2195s 76s/step - loss: 0.0048 - accuracy: 0.2144\n",
      "Epoch 470/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 11s 387ms/step - loss: 0.0047 - accuracy: 0.2306\n",
      "Epoch 471/1000\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.0048 - accuracy: 0.2188\n",
      "Epoch 472/1000\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.0047 - accuracy: 0.2241\n",
      "Epoch 473/1000\n",
      "29/29 [==============================] - 10s 356ms/step - loss: 0.0047 - accuracy: 0.2144\n",
      "Epoch 474/1000\n",
      "29/29 [==============================] - 9s 315ms/step - loss: 0.0047 - accuracy: 0.2317\n",
      "Epoch 475/1000\n",
      "29/29 [==============================] - 9s 309ms/step - loss: 0.0048 - accuracy: 0.2166\n",
      "Epoch 476/1000\n",
      "29/29 [==============================] - 10s 334ms/step - loss: 0.0047 - accuracy: 0.2188\n",
      "Epoch 477/1000\n",
      "29/29 [==============================] - 9s 321ms/step - loss: 0.0047 - accuracy: 0.2198\n",
      "Epoch 478/1000\n",
      "29/29 [==============================] - 10s 329ms/step - loss: 0.0047 - accuracy: 0.2241\n",
      "Epoch 479/1000\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.0047 - accuracy: 0.2231\n",
      "Epoch 480/1000\n",
      "29/29 [==============================] - 9s 319ms/step - loss: 0.0046 - accuracy: 0.2209\n",
      "Epoch 481/1000\n",
      "29/29 [==============================] - 8s 293ms/step - loss: 0.0046 - accuracy: 0.2231\n",
      "Epoch 482/1000\n",
      "29/29 [==============================] - 8s 286ms/step - loss: 0.0046 - accuracy: 0.2188\n",
      "Epoch 483/1000\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.0046 - accuracy: 0.2198\n",
      "Epoch 484/1000\n",
      "29/29 [==============================] - 9s 307ms/step - loss: 0.0047 - accuracy: 0.2241\n",
      "Epoch 485/1000\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.0046 - accuracy: 0.2198\n",
      "Epoch 486/1000\n",
      "29/29 [==============================] - 9s 293ms/step - loss: 0.0046 - accuracy: 0.2188\n",
      "Epoch 487/1000\n",
      "29/29 [==============================] - 8s 280ms/step - loss: 0.0045 - accuracy: 0.2317\n",
      "Epoch 488/1000\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.0046 - accuracy: 0.2134\n",
      "Epoch 489/1000\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.0046 - accuracy: 0.2241\n",
      "Epoch 490/1000\n",
      "29/29 [==============================] - 8s 278ms/step - loss: 0.0046 - accuracy: 0.2252\n",
      "Epoch 491/1000\n",
      "29/29 [==============================] - 9s 324ms/step - loss: 0.0045 - accuracy: 0.2231\n",
      "Epoch 492/1000\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.0046 - accuracy: 0.2284\n",
      "Epoch 493/1000\n",
      "29/29 [==============================] - 8s 291ms/step - loss: 0.0045 - accuracy: 0.2177\n",
      "Epoch 494/1000\n",
      "29/29 [==============================] - 9s 317ms/step - loss: 0.0045 - accuracy: 0.2123\n",
      "Epoch 495/1000\n",
      "29/29 [==============================] - 9s 308ms/step - loss: 0.0045 - accuracy: 0.2306\n",
      "Epoch 496/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.0045 - accuracy: 0.2188\n",
      "Epoch 497/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.0045 - accuracy: 0.2317\n",
      "Epoch 498/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.0044 - accuracy: 0.2037\n",
      "Epoch 499/1000\n",
      "29/29 [==============================] - 9s 293ms/step - loss: 0.0045 - accuracy: 0.2317\n",
      "Epoch 500/1000\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.0044 - accuracy: 0.2263\n",
      "Epoch 501/1000\n",
      "29/29 [==============================] - 12s 401ms/step - loss: 0.0044 - accuracy: 0.2220\n",
      "Epoch 502/1000\n",
      "29/29 [==============================] - 9s 321ms/step - loss: 0.0045 - accuracy: 0.2263\n",
      "Epoch 503/1000\n",
      "29/29 [==============================] - 13s 439ms/step - loss: 0.0044 - accuracy: 0.2134\n",
      "Epoch 504/1000\n",
      "29/29 [==============================] - 13s 433ms/step - loss: 0.0045 - accuracy: 0.2360\n",
      "Epoch 505/1000\n",
      "29/29 [==============================] - 10s 329ms/step - loss: 0.0043 - accuracy: 0.2274\n",
      "Epoch 506/1000\n",
      "29/29 [==============================] - 9s 307ms/step - loss: 0.0044 - accuracy: 0.2144\n",
      "Epoch 507/1000\n",
      "29/29 [==============================] - 11s 391ms/step - loss: 0.0044 - accuracy: 0.2220\n",
      "Epoch 508/1000\n",
      "29/29 [==============================] - 9s 316ms/step - loss: 0.0044 - accuracy: 0.2231\n",
      "Epoch 509/1000\n",
      "29/29 [==============================] - 11s 369ms/step - loss: 0.0044 - accuracy: 0.2220\n",
      "Epoch 510/1000\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 0.0044 - accuracy: 0.2252\n",
      "Epoch 511/1000\n",
      "29/29 [==============================] - 11s 375ms/step - loss: 0.0043 - accuracy: 0.2166\n",
      "Epoch 512/1000\n",
      "29/29 [==============================] - 11s 377ms/step - loss: 0.0044 - accuracy: 0.2241\n",
      "Epoch 513/1000\n",
      "29/29 [==============================] - 10s 341ms/step - loss: 0.0044 - accuracy: 0.2220\n",
      "Epoch 514/1000\n",
      "29/29 [==============================] - 9s 327ms/step - loss: 0.0043 - accuracy: 0.2306\n",
      "Epoch 515/1000\n",
      "29/29 [==============================] - 9s 325ms/step - loss: 0.0044 - accuracy: 0.2252\n",
      "Epoch 516/1000\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.0043 - accuracy: 0.2166\n",
      "Epoch 517/1000\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.0043 - accuracy: 0.2295\n",
      "Epoch 518/1000\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.0043 - accuracy: 0.2198\n",
      "Epoch 519/1000\n",
      "29/29 [==============================] - 8s 291ms/step - loss: 0.0043 - accuracy: 0.2263\n",
      "Epoch 520/1000\n",
      "29/29 [==============================] - 8s 293ms/step - loss: 0.0043 - accuracy: 0.2155\n",
      "Epoch 521/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0043 - accuracy: 0.2091\n",
      "Epoch 522/1000\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.0044 - accuracy: 0.2284\n",
      "Epoch 523/1000\n",
      "29/29 [==============================] - 8s 293ms/step - loss: 0.0043 - accuracy: 0.2360\n",
      "Epoch 524/1000\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.0042 - accuracy: 0.2134\n",
      "Epoch 525/1000\n",
      "29/29 [==============================] - 8s 293ms/step - loss: 0.0042 - accuracy: 0.2252\n",
      "Epoch 526/1000\n",
      "29/29 [==============================] - 8s 287ms/step - loss: 0.0043 - accuracy: 0.2134\n",
      "Epoch 527/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.0043 - accuracy: 0.2317\n",
      "Epoch 528/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.0042 - accuracy: 0.2231\n",
      "Epoch 529/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.0043 - accuracy: 0.2177\n",
      "Epoch 530/1000\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.0042 - accuracy: 0.2263\n",
      "Epoch 531/1000\n",
      "29/29 [==============================] - 11s 366ms/step - loss: 0.0043 - accuracy: 0.2209\n",
      "Epoch 532/1000\n",
      "29/29 [==============================] - 9s 310ms/step - loss: 3.1822 - accuracy: 0.2198\n",
      "Epoch 533/1000\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.0042 - accuracy: 0.2252\n",
      "Epoch 534/1000\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.0041 - accuracy: 0.2144\n",
      "Epoch 535/1000\n",
      "29/29 [==============================] - 11s 369ms/step - loss: 0.0043 - accuracy: 0.2263\n",
      "Epoch 536/1000\n",
      "29/29 [==============================] - 10s 360ms/step - loss: 0.0042 - accuracy: 0.2209\n",
      "Epoch 537/1000\n",
      "29/29 [==============================] - 10s 332ms/step - loss: 0.0042 - accuracy: 0.2144\n",
      "Epoch 538/1000\n",
      "29/29 [==============================] - 10s 339ms/step - loss: 0.0042 - accuracy: 0.2188\n",
      "Epoch 539/1000\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.0042 - accuracy: 0.2188\n",
      "Epoch 540/1000\n",
      "29/29 [==============================] - 10s 328ms/step - loss: 0.0042 - accuracy: 0.2177\n",
      "Epoch 541/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.0042 - accuracy: 0.2220\n",
      "Epoch 542/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0042 - accuracy: 0.2155\n",
      "Epoch 543/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.0042 - accuracy: 0.2284\n",
      "Epoch 544/1000\n",
      "29/29 [==============================] - 9s 307ms/step - loss: 0.0042 - accuracy: 0.2220\n",
      "Epoch 545/1000\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.0041 - accuracy: 0.2058\n",
      "Epoch 546/1000\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.0042 - accuracy: 0.2231\n",
      "Epoch 547/1000\n",
      "29/29 [==============================] - 8s 293ms/step - loss: 0.0041 - accuracy: 0.2274\n",
      "Epoch 548/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 8s 288ms/step - loss: 0.0042 - accuracy: 0.2166\n",
      "Epoch 549/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.0042 - accuracy: 0.2252\n",
      "Epoch 550/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.0041 - accuracy: 0.2080\n",
      "Epoch 551/1000\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.0041 - accuracy: 0.2134\n",
      "Epoch 552/1000\n",
      "29/29 [==============================] - 8s 285ms/step - loss: 0.0042 - accuracy: 0.2274\n",
      "Epoch 553/1000\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.0041 - accuracy: 0.2220\n",
      "Epoch 554/1000\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.0041 - accuracy: 0.2252\n",
      "Epoch 555/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.0041 - accuracy: 0.2134\n",
      "Epoch 556/1000\n",
      "29/29 [==============================] - 8s 285ms/step - loss: 0.0042 - accuracy: 0.2241\n",
      "Epoch 557/1000\n",
      "29/29 [==============================] - 8s 291ms/step - loss: 0.0041 - accuracy: 0.2198\n",
      "Epoch 558/1000\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.0041 - accuracy: 0.2155\n",
      "Epoch 559/1000\n",
      "29/29 [==============================] - 8s 285ms/step - loss: 0.0041 - accuracy: 0.2295\n",
      "Epoch 560/1000\n",
      "29/29 [==============================] - 8s 283ms/step - loss: 0.0040 - accuracy: 0.1929\n",
      "Epoch 561/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0041 - accuracy: 0.2231\n",
      "Epoch 562/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0041 - accuracy: 0.2198\n",
      "Epoch 563/1000\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.0041 - accuracy: 0.2274\n",
      "Epoch 564/1000\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.0041 - accuracy: 0.2144\n",
      "Epoch 565/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0040 - accuracy: 0.2306\n",
      "Epoch 566/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.0042 - accuracy: 0.2091\n",
      "Epoch 567/1000\n",
      "29/29 [==============================] - 9s 293ms/step - loss: 0.0040 - accuracy: 0.2209\n",
      "Epoch 568/1000\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.0041 - accuracy: 0.2220\n",
      "Epoch 569/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0041 - accuracy: 0.2198\n",
      "Epoch 570/1000\n",
      "29/29 [==============================] - 8s 293ms/step - loss: 0.0041 - accuracy: 0.2220\n",
      "Epoch 571/1000\n",
      "29/29 [==============================] - 10s 338ms/step - loss: 0.0041 - accuracy: 0.2209\n",
      "Epoch 572/1000\n",
      "29/29 [==============================] - 10s 346ms/step - loss: 0.0041 - accuracy: 0.2155\n",
      "Epoch 573/1000\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.0040 - accuracy: 0.2177\n",
      "Epoch 574/1000\n",
      "29/29 [==============================] - 9s 319ms/step - loss: 0.0041 - accuracy: 0.2198\n",
      "Epoch 575/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.0040 - accuracy: 0.2295\n",
      "Epoch 576/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.0040 - accuracy: 0.2069\n",
      "Epoch 577/1000\n",
      "29/29 [==============================] - 10s 350ms/step - loss: 0.0041 - accuracy: 0.2209\n",
      "Epoch 578/1000\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.0040 - accuracy: 0.2209\n",
      "Epoch 579/1000\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.0041 - accuracy: 0.2166\n",
      "Epoch 580/1000\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.0040 - accuracy: 0.2252\n",
      "Epoch 581/1000\n",
      "29/29 [==============================] - 9s 307ms/step - loss: 0.0041 - accuracy: 0.2209\n",
      "Epoch 582/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0040 - accuracy: 0.2123\n",
      "Epoch 583/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.0041 - accuracy: 0.2338\n",
      "Epoch 584/1000\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.0039 - accuracy: 0.2112\n",
      "Epoch 585/1000\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.0040 - accuracy: 0.2144\n",
      "Epoch 586/1000\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.0041 - accuracy: 0.2177\n",
      "Epoch 587/1000\n",
      "29/29 [==============================] - 9s 293ms/step - loss: 0.0040 - accuracy: 0.2209\n",
      "Epoch 588/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0040 - accuracy: 0.2198\n",
      "Epoch 589/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.0040 - accuracy: 0.2295\n",
      "Epoch 590/1000\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.0040 - accuracy: 0.2166\n",
      "Epoch 591/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0040 - accuracy: 0.1983\n",
      "Epoch 592/1000\n",
      "29/29 [==============================] - 11s 378ms/step - loss: 0.0040 - accuracy: 0.2338\n",
      "Epoch 593/1000\n",
      "29/29 [==============================] - 10s 354ms/step - loss: 0.0040 - accuracy: 0.2166\n",
      "Epoch 594/1000\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.0040 - accuracy: 0.2241\n",
      "Epoch 595/1000\n",
      "29/29 [==============================] - 11s 364ms/step - loss: 0.0040 - accuracy: 0.2198\n",
      "Epoch 596/1000\n",
      "29/29 [==============================] - 12s 430ms/step - loss: 0.0040 - accuracy: 0.2155\n",
      "Epoch 597/1000\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.0040 - accuracy: 0.2274\n",
      "Epoch 598/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.0040 - accuracy: 0.2112\n",
      "Epoch 599/1000\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.0040 - accuracy: 0.2220\n",
      "Epoch 600/1000\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.0040 - accuracy: 0.2188\n",
      "Epoch 601/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.0040 - accuracy: 0.2198\n",
      "Epoch 602/1000\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.0040 - accuracy: 0.2209\n",
      "Epoch 603/1000\n",
      "29/29 [==============================] - 11s 391ms/step - loss: 0.0039 - accuracy: 0.2220\n",
      "Epoch 604/1000\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 0.0039 - accuracy: 0.2112\n",
      "Epoch 605/1000\n",
      "29/29 [==============================] - 9s 293ms/step - loss: 0.0040 - accuracy: 0.2231\n",
      "Epoch 606/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.0039 - accuracy: 0.2188\n",
      "Epoch 607/1000\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.0040 - accuracy: 0.2155\n",
      "Epoch 608/1000\n",
      "29/29 [==============================] - 8s 286ms/step - loss: 0.0039 - accuracy: 0.2349\n",
      "Epoch 609/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.0040 - accuracy: 0.2123\n",
      "Epoch 610/1000\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.0039 - accuracy: 0.2080\n",
      "Epoch 611/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.0040 - accuracy: 0.2284\n",
      "Epoch 612/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.0040 - accuracy: 0.2220\n",
      "Epoch 613/1000\n",
      "29/29 [==============================] - 8s 293ms/step - loss: 0.0039 - accuracy: 0.2134\n",
      "Epoch 614/1000\n",
      "29/29 [==============================] - 9s 317ms/step - loss: 0.0040 - accuracy: 0.2295\n",
      "Epoch 615/1000\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.0039 - accuracy: 0.1972\n",
      "Epoch 616/1000\n",
      "29/29 [==============================] - 8s 287ms/step - loss: 0.0039 - accuracy: 0.2317\n",
      "Epoch 617/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.0040 - accuracy: 0.2317\n",
      "Epoch 618/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.0039 - accuracy: 0.2177\n",
      "Epoch 619/1000\n",
      "29/29 [==============================] - 9s 308ms/step - loss: 0.0039 - accuracy: 0.2209\n",
      "Epoch 620/1000\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.0039 - accuracy: 0.2026\n",
      "Epoch 621/1000\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.0040 - accuracy: 0.2349\n",
      "Epoch 622/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.0039 - accuracy: 0.2112\n",
      "Epoch 623/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.0039 - accuracy: 0.2188\n",
      "Epoch 624/1000\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.0039 - accuracy: 0.2155\n",
      "Epoch 625/1000\n",
      "29/29 [==============================] - 8s 285ms/step - loss: 0.0039 - accuracy: 0.2177\n",
      "Epoch 626/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 8s 293ms/step - loss: 0.0039 - accuracy: 0.2295\n",
      "Epoch 627/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0039 - accuracy: 0.2080\n",
      "Epoch 628/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.0039 - accuracy: 0.2252\n",
      "Epoch 629/1000\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.0039 - accuracy: 0.2188\n",
      "Epoch 630/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0039 - accuracy: 0.2166\n",
      "Epoch 631/1000\n",
      "29/29 [==============================] - 11s 364ms/step - loss: 0.0039 - accuracy: 0.2209\n",
      "Epoch 632/1000\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 0.0039 - accuracy: 0.2231\n",
      "Epoch 633/1000\n",
      "29/29 [==============================] - 9s 308ms/step - loss: 0.0039 - accuracy: 0.2134\n",
      "Epoch 634/1000\n",
      "29/29 [==============================] - 10s 348ms/step - loss: 0.0039 - accuracy: 0.2220\n",
      "Epoch 635/1000\n",
      "29/29 [==============================] - 10s 360ms/step - loss: 0.0039 - accuracy: 0.2198\n",
      "Epoch 636/1000\n",
      "29/29 [==============================] - 10s 343ms/step - loss: 0.0039 - accuracy: 0.2209\n",
      "Epoch 637/1000\n",
      "29/29 [==============================] - 9s 317ms/step - loss: 0.0039 - accuracy: 0.2166\n",
      "Epoch 638/1000\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.0039 - accuracy: 0.2274\n",
      "Epoch 639/1000\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.0039 - accuracy: 0.2004\n",
      "Epoch 640/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.0039 - accuracy: 0.2220\n",
      "Epoch 641/1000\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.0038 - accuracy: 0.2489\n",
      "Epoch 642/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.0039 - accuracy: 0.1961\n",
      "Epoch 643/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.0039 - accuracy: 0.2177\n",
      "Epoch 644/1000\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.0039 - accuracy: 0.2220\n",
      "Epoch 645/1000\n",
      "29/29 [==============================] - 8s 287ms/step - loss: 0.0038 - accuracy: 0.2274\n",
      "Epoch 646/1000\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.0039 - accuracy: 0.2209\n",
      "Epoch 647/1000\n",
      "29/29 [==============================] - 8s 291ms/step - loss: 0.0038 - accuracy: 0.2220\n",
      "Epoch 648/1000\n",
      "29/29 [==============================] - 9s 319ms/step - loss: 0.0039 - accuracy: 0.2220\n",
      "Epoch 649/1000\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.0039 - accuracy: 0.2069\n",
      "Epoch 650/1000\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.0038 - accuracy: 0.2231\n",
      "Epoch 651/1000\n",
      "29/29 [==============================] - 9s 308ms/step - loss: 0.0039 - accuracy: 0.2155\n",
      "Epoch 652/1000\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.0038 - accuracy: 0.2188\n",
      "Epoch 653/1000\n",
      "29/29 [==============================] - 8s 293ms/step - loss: 0.0039 - accuracy: 0.2166\n",
      "Epoch 654/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.0039 - accuracy: 0.2198\n",
      "Epoch 655/1000\n",
      "29/29 [==============================] - 8s 291ms/step - loss: 0.0038 - accuracy: 0.2263\n",
      "Epoch 656/1000\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.0039 - accuracy: 0.2155\n",
      "Epoch 657/1000\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.0038 - accuracy: 0.2209\n",
      "Epoch 658/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.0038 - accuracy: 0.2166\n",
      "Epoch 659/1000\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.0038 - accuracy: 0.2231\n",
      "Epoch 660/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.0038 - accuracy: 0.2220\n",
      "Epoch 661/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.0038 - accuracy: 0.2166\n",
      "Epoch 662/1000\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.0039 - accuracy: 0.2188\n",
      "Epoch 663/1000\n",
      "29/29 [==============================] - 8s 284ms/step - loss: 0.0039 - accuracy: 0.2144\n",
      "Epoch 664/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0038 - accuracy: 0.2209\n",
      "Epoch 665/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0039 - accuracy: 0.2177\n",
      "Epoch 666/1000\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.0039 - accuracy: 0.2263\n",
      "Epoch 667/1000\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.0038 - accuracy: 0.2134\n",
      "Epoch 668/1000\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.0038 - accuracy: 0.2220\n",
      "Epoch 669/1000\n",
      "29/29 [==============================] - 8s 284ms/step - loss: 0.0039 - accuracy: 0.2101\n",
      "Epoch 670/1000\n",
      "29/29 [==============================] - 309s 11s/step - loss: 0.0038 - accuracy: 0.2360\n",
      "Epoch 671/1000\n",
      "29/29 [==============================] - 12s 424ms/step - loss: 0.0039 - accuracy: 0.2306\n",
      "Epoch 672/1000\n",
      "29/29 [==============================] - 11s 370ms/step - loss: 0.0039 - accuracy: 0.1983\n",
      "Epoch 673/1000\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.0038 - accuracy: 0.2101\n",
      "Epoch 674/1000\n",
      "29/29 [==============================] - 10s 339ms/step - loss: 0.0038 - accuracy: 0.2317\n",
      "Epoch 675/1000\n",
      "29/29 [==============================] - 9s 317ms/step - loss: 0.0038 - accuracy: 0.2317\n",
      "Epoch 676/1000\n",
      "29/29 [==============================] - 8s 287ms/step - loss: 0.0038 - accuracy: 0.2112\n",
      "Epoch 677/1000\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.0038 - accuracy: 0.2015\n",
      "Epoch 678/1000\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.0039 - accuracy: 0.2295\n",
      "Epoch 679/1000\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.0038 - accuracy: 0.2144\n",
      "Epoch 680/1000\n",
      "29/29 [==============================] - 9s 323ms/step - loss: 0.0038 - accuracy: 0.2263\n",
      "Epoch 681/1000\n",
      "29/29 [==============================] - 10s 330ms/step - loss: 0.0039 - accuracy: 0.2274\n",
      "Epoch 682/1000\n",
      "29/29 [==============================] - 10s 361ms/step - loss: 0.0038 - accuracy: 0.2123\n",
      "Epoch 683/1000\n",
      "29/29 [==============================] - 17s 595ms/step - loss: 0.0038 - accuracy: 0.2134\n",
      "Epoch 684/1000\n",
      "29/29 [==============================] - 17s 570ms/step - loss: 0.0038 - accuracy: 0.2252\n",
      "Epoch 685/1000\n",
      "29/29 [==============================] - 11s 396ms/step - loss: 0.0038 - accuracy: 0.2177\n",
      "Epoch 686/1000\n",
      "29/29 [==============================] - 10s 340ms/step - loss: 0.0038 - accuracy: 0.2198\n",
      "Epoch 687/1000\n",
      "29/29 [==============================] - 10s 338ms/step - loss: 0.0038 - accuracy: 0.2188\n",
      "Epoch 688/1000\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.0038 - accuracy: 0.2231\n",
      "Epoch 689/1000\n",
      "29/29 [==============================] - 10s 335ms/step - loss: 0.0038 - accuracy: 0.2166\n",
      "Epoch 690/1000\n",
      "29/29 [==============================] - 9s 327ms/step - loss: 0.0038 - accuracy: 0.2198\n",
      "Epoch 691/1000\n",
      "29/29 [==============================] - 10s 330ms/step - loss: 0.0038 - accuracy: 0.2198\n",
      "Epoch 692/1000\n",
      "29/29 [==============================] - 10s 345ms/step - loss: 0.0038 - accuracy: 0.2198\n",
      "Epoch 693/1000\n",
      "29/29 [==============================] - 10s 345ms/step - loss: 0.0038 - accuracy: 0.2177\n",
      "Epoch 694/1000\n",
      "29/29 [==============================] - 9s 326ms/step - loss: 0.0038 - accuracy: 0.2231\n",
      "Epoch 695/1000\n",
      "29/29 [==============================] - 11s 378ms/step - loss: 0.0038 - accuracy: 0.2198\n",
      "Epoch 696/1000\n",
      "29/29 [==============================] - 10s 359ms/step - loss: 0.0038 - accuracy: 0.2198\n",
      "Epoch 697/1000\n",
      "29/29 [==============================] - 10s 346ms/step - loss: 0.0038 - accuracy: 0.2134\n",
      "Epoch 698/1000\n",
      "29/29 [==============================] - 11s 391ms/step - loss: 0.0038 - accuracy: 0.2220\n",
      "Epoch 699/1000\n",
      "29/29 [==============================] - 12s 427ms/step - loss: 0.0038 - accuracy: 0.2198\n",
      "Epoch 700/1000\n",
      "29/29 [==============================] - 11s 382ms/step - loss: 0.0037 - accuracy: 0.2306\n",
      "Epoch 701/1000\n",
      "29/29 [==============================] - 9s 310ms/step - loss: 0.0038 - accuracy: 0.2015\n",
      "Epoch 702/1000\n",
      "29/29 [==============================] - 10s 333ms/step - loss: 0.0038 - accuracy: 0.2284\n",
      "Epoch 703/1000\n",
      "29/29 [==============================] - 10s 350ms/step - loss: 0.0038 - accuracy: 0.2209\n",
      "Epoch 704/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 12s 400ms/step - loss: 0.0037 - accuracy: 0.2252\n",
      "Epoch 705/1000\n",
      "29/29 [==============================] - 9s 324ms/step - loss: 0.0039 - accuracy: 0.2166\n",
      "Epoch 706/1000\n",
      "29/29 [==============================] - 9s 322ms/step - loss: 0.0038 - accuracy: 0.2177\n",
      "Epoch 707/1000\n",
      "29/29 [==============================] - 10s 329ms/step - loss: 0.0039 - accuracy: 0.2295\n",
      "Epoch 708/1000\n",
      "29/29 [==============================] - 11s 367ms/step - loss: 0.0038 - accuracy: 0.2037\n",
      "Epoch 709/1000\n",
      "29/29 [==============================] - 8s 291ms/step - loss: 0.0037 - accuracy: 0.2144\n",
      "Epoch 710/1000\n",
      "29/29 [==============================] - 9s 324ms/step - loss: 0.0038 - accuracy: 0.2284\n",
      "Epoch 711/1000\n",
      "29/29 [==============================] - 9s 320ms/step - loss: 0.0038 - accuracy: 0.2144\n",
      "Epoch 712/1000\n",
      "29/29 [==============================] - 10s 348ms/step - loss: 0.0038 - accuracy: 0.2252\n",
      "Epoch 713/1000\n",
      "29/29 [==============================] - 8s 287ms/step - loss: 0.0037 - accuracy: 0.2080\n",
      "Epoch 714/1000\n",
      "29/29 [==============================] - 502s 17s/step - loss: 0.0039 - accuracy: 0.2306\n",
      "Epoch 715/1000\n",
      "29/29 [==============================] - 15s 524ms/step - loss: 0.0038 - accuracy: 0.2220\n",
      "Epoch 716/1000\n",
      "29/29 [==============================] - 13s 459ms/step - loss: 0.0038 - accuracy: 0.2188\n",
      "Epoch 717/1000\n",
      "29/29 [==============================] - 13s 460ms/step - loss: 0.0038 - accuracy: 0.2155\n",
      "Epoch 718/1000\n",
      "29/29 [==============================] - 13s 438ms/step - loss: 0.0038 - accuracy: 0.2188\n",
      "Epoch 719/1000\n",
      "29/29 [==============================] - 13s 463ms/step - loss: 0.0038 - accuracy: 0.2155\n",
      "Epoch 720/1000\n",
      "29/29 [==============================] - 13s 459ms/step - loss: 0.0038 - accuracy: 0.2241\n",
      "Epoch 721/1000\n",
      "29/29 [==============================] - 11s 392ms/step - loss: 0.0038 - accuracy: 0.2123\n",
      "Epoch 722/1000\n",
      "29/29 [==============================] - 10s 353ms/step - loss: 0.0038 - accuracy: 0.2328\n",
      "Epoch 723/1000\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.0038 - accuracy: 0.2177\n",
      "Epoch 724/1000\n",
      "29/29 [==============================] - 12s 400ms/step - loss: 0.0038 - accuracy: 0.2004\n",
      "Epoch 725/1000\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.0037 - accuracy: 0.2252\n",
      "Epoch 726/1000\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.0038 - accuracy: 0.2198\n",
      "Epoch 727/1000\n",
      "29/29 [==============================] - 9s 317ms/step - loss: 0.0038 - accuracy: 0.2241\n",
      "Epoch 728/1000\n",
      "29/29 [==============================] - 8s 291ms/step - loss: 0.0037 - accuracy: 0.2209\n",
      "Epoch 729/1000\n",
      "29/29 [==============================] - 11s 372ms/step - loss: 0.0038 - accuracy: 0.2198\n",
      "Epoch 730/1000\n",
      "29/29 [==============================] - 11s 383ms/step - loss: 0.0038 - accuracy: 0.2188\n",
      "Epoch 731/1000\n",
      "29/29 [==============================] - 11s 371ms/step - loss: 0.0038 - accuracy: 0.2295\n",
      "Epoch 732/1000\n",
      "29/29 [==============================] - 10s 336ms/step - loss: 0.0038 - accuracy: 0.1983\n",
      "Epoch 733/1000\n",
      "29/29 [==============================] - 12s 401ms/step - loss: 0.0038 - accuracy: 0.2263\n",
      "Epoch 734/1000\n",
      "29/29 [==============================] - 12s 398ms/step - loss: 0.0038 - accuracy: 0.2338\n",
      "Epoch 735/1000\n",
      "29/29 [==============================] - 10s 353ms/step - loss: 0.0037 - accuracy: 0.2080\n",
      "Epoch 736/1000\n",
      "29/29 [==============================] - 10s 349ms/step - loss: 0.0038 - accuracy: 0.2306\n",
      "Epoch 737/1000\n",
      "29/29 [==============================] - 10s 352ms/step - loss: 0.0038 - accuracy: 0.2188\n",
      "Epoch 738/1000\n",
      "29/29 [==============================] - 10s 349ms/step - loss: 0.0037 - accuracy: 0.2101\n",
      "Epoch 739/1000\n",
      "29/29 [==============================] - 10s 333ms/step - loss: 0.0038 - accuracy: 0.2177\n",
      "Epoch 740/1000\n",
      "29/29 [==============================] - 10s 331ms/step - loss: 0.0037 - accuracy: 0.2069\n",
      "Epoch 741/1000\n",
      "29/29 [==============================] - 10s 353ms/step - loss: 0.0038 - accuracy: 0.2349\n",
      "Epoch 742/1000\n",
      "29/29 [==============================] - 11s 374ms/step - loss: 0.0038 - accuracy: 0.2198\n",
      "Epoch 743/1000\n",
      "29/29 [==============================] - 10s 335ms/step - loss: 0.0038 - accuracy: 0.2080\n",
      "Epoch 744/1000\n",
      "29/29 [==============================] - 11s 388ms/step - loss: 0.0037 - accuracy: 0.2349\n",
      "Epoch 745/1000\n",
      "29/29 [==============================] - 9s 326ms/step - loss: 0.0038 - accuracy: 0.2091\n",
      "Epoch 746/1000\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.0038 - accuracy: 0.2328\n",
      "Epoch 747/1000\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.0038 - accuracy: 0.2155\n",
      "Epoch 748/1000\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.0037 - accuracy: 0.2134\n",
      "Epoch 749/1000\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.0037 - accuracy: 0.2188\n",
      "Epoch 750/1000\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.0038 - accuracy: 0.2231\n",
      "Epoch 751/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0038 - accuracy: 0.2177\n",
      "Epoch 752/1000\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.0037 - accuracy: 0.2134\n",
      "Epoch 753/1000\n",
      "29/29 [==============================] - 8s 285ms/step - loss: 0.0038 - accuracy: 0.2328\n",
      "Epoch 754/1000\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.0037 - accuracy: 0.2112\n",
      "Epoch 755/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0038 - accuracy: 0.2123\n",
      "Epoch 756/1000\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.0038 - accuracy: 0.2220\n",
      "Epoch 757/1000\n",
      "29/29 [==============================] - 8s 291ms/step - loss: 0.0037 - accuracy: 0.2284\n",
      "Epoch 758/1000\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.0037 - accuracy: 0.2198\n",
      "Epoch 759/1000\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.0037 - accuracy: 0.2166\n",
      "Epoch 760/1000\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.0038 - accuracy: 0.2091\n",
      "Epoch 761/1000\n",
      "29/29 [==============================] - 8s 291ms/step - loss: 0.0037 - accuracy: 0.2263\n",
      "Epoch 762/1000\n",
      "29/29 [==============================] - 9s 317ms/step - loss: 0.0037 - accuracy: 0.2252\n",
      "Epoch 763/1000\n",
      "29/29 [==============================] - 13s 448ms/step - loss: 0.0038 - accuracy: 0.2155\n",
      "Epoch 764/1000\n",
      " 2/29 [=>............................] - ETA: 5s - loss: 0.0036 - accuracy: 0.2188"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-001d7d65ee25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/gas-chromatography-nZn5FIuy/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/gas-chromatography-nZn5FIuy/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/gas-chromatography-nZn5FIuy/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/gas-chromatography-nZn5FIuy/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/gas-chromatography-nZn5FIuy/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/gas-chromatography-nZn5FIuy/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/gas-chromatography-nZn5FIuy/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/gas-chromatography-nZn5FIuy/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/share/virtualenvs/gas-chromatography-nZn5FIuy/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(dataset, epochs=1000, steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(intensities_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 170\n",
    "intensities = intensities_array[index]\n",
    "labels = labels_array[index]\n",
    "peak_start_times = times[labels==1]\n",
    "peak_start_intensities = intensities[labels==1]\n",
    "predictions_per_data = predictions[index]\n",
    "predicted_peak_start_times = times[predictions_per_data > 0.12]\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(\n",
    "    times, intensities, '--',\n",
    "    peak_start_times, peak_start_intensities, 'x'\n",
    ")\n",
    "for predicted_peak_start_time in predicted_peak_start_times:\n",
    "    plt.axvline(x=predicted_peak_start_time, color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
